[project]
LOCAL_PATH = /home/ubuntu/Disco_llama/Retriever

[data]
CORPUS_PATH = data/
FILES_FORMAT = *.pdf
CORPUS_LOADER = PyPDFLoader

[data_parsing]
CHUNK_SIZE = 250
CHUNK_OVERLAP = 50
DB_FAISS_PATH = vectorstore/db_faiss

[retriever]
VECTOR_COUNT = 2
RETURN_SOURCE_DOCUMENTS = True

[model]
MODEL_TYPE = llama
HUGGINGFACE_REPO_ID = TheBloke/Llama-2-7B-Chat-GGML
MODEL_NAME = llama-2-7b-chat.ggmlv3.q8_0.bin
MODEL_LOCAL_REPO = models/
MAX_NEW_TOKENS = 256
TEMPERATURE = 0.01

[task]
QA_TEMPLATE = Use the following pieces of information to answer the user's question.
    If you don't know the answer, just say that you don't know, don't try to make up an answer.


    Context: {context}
    Question: {question}

    Return a detailled answer using an epic style.


[QUESTIONS]
QUESTION1 = What is the sport that wizards play with broomsicks? 
QUESTION2 = Who teaches Potions?
QUESTION3 = What is the name of Ron's rat?
QUESTION4 = What is the story of Nicholas Flamel?